# SIEVE — Synthetic Inspection, Editing & Validation Engine

A review UI for human-in-the-loop validation of synthetic Q&A datasets generated by the RAG Evaluation Framework's `synthetic_datagen` module.

**Predecessor:** SAGE Review Tool (same concept, single-citation only, hardcoded paths, limited filtering).
**Companion:** `rag-evaluation-framework/synthetic_datagen` (generates the data SIEVE reviews).

---

## What SIEVE Does

SIEVE takes the `output.jsonl` produced by `synthetic_datagen.GenerationPipeline`, lets a human reviewer inspect every query-citation pair against the original KB documents, edit/add/remove citations, accept or reject items, add notes, and upload the approved dataset to LangSmith for evaluation.

### Key Differences from SAGE Review Tool

| Aspect | SAGE | SIEVE |
|--------|------|-------|
| KB loading | Hardcoded path in backend config | User uploads/selects KB folder via UI |
| File format | Single citation per item (`doc_id`, `citation`, `start_index`, `end_index`) | Multi-citation per item (`citations: [{doc_id, text, start_index, end_index, chunks}]`) |
| Citation editing | Override single citation from current doc only | Add citations from any KB doc, remove individual citations, edit existing |
| Filtering | Status filter + text search | Status + category + language + doc_id + has_typos filters, text search |
| Real queries | Not loaded | Optional: load real queries for side-by-side style comparison |
| Data source | Auto-reads from sibling `output.jsonl` | User selects/uploads the output.jsonl file |

---

## Core Workflow

```
1. LOAD
   User opens SIEVE → prompted to:
   ├── Select KB folder (directory of .md files)
   ├── Select output.jsonl (synthetic data to review)
   └── (Optional) Select queries.json (real production queries for reference)

2. REVIEW
   Three-panel layout:
   ├── Left: Query list with filters & search
   ├── Center: Detail panel (query, citations, metadata, notes, actions)
   └── Right: KB document viewer with citation highlighting

3. EXPORT
   ├── Writes review.jsonl (copy of output with review decisions)
   └── Upload accepted items to LangSmith
```

---

## Data Model

### Input: `output.jsonl` (from synthetic_datagen)

Each line is a `SyntheticDataItem`:

```json
{
  "query": "how much does the pro plan cost?",
  "citations": [
    {
      "doc_id": "pricing.md",
      "text": "**Pro Plan** - $29/month",
      "start_index": 245,
      "end_index": 269,
      "chunks": ["Full pricing section..."]
    }
  ],
  "category": "pricing",
  "subcategory": "plans",
  "source": ["https://example.com/pricing"],
  "query_metadata": {
    "language": "en",
    "has_typos": false,
    "tone": "casual",
    "style": "question"
  }
}
```

### Output: `review.jsonl`

Same structure plus review fields:

```json
{
  "...all SyntheticDataItem fields...",
  "review_status": "accepted | rejected | pending",
  "reviewer_notes": "Looks good, citation is accurate",
  "citations_modified": true,
  "original_citations": [ "...snapshot of citations before any edits..." ]
}
```

The `original_citations` field preserves the pipeline output so edits are traceable.

---

## UI Layout

### 1. Setup Screen (shown on first load / no data loaded)

A clean landing page with three drop zones / file pickers:

- **KB Folder** (required): Select a directory containing `.md` files. Validates that at least one `.md` file exists. Shows count after loading ("12 documents loaded").
- **Output File** (required): Select an `output.jsonl` file. Validates it parses as JSONL with expected fields. Shows count ("87 items loaded").
- **Real Queries** (optional): Select a `queries.json` file for reference. Shows count if loaded.

A "Start Review" button activates once KB + output are loaded.

### 2. Main Review Screen

#### Top Toolbar (fixed, ~60px)
- **Title**: "SIEVE"
- **Progress stats**: `X/Y reviewed` | `Z accepted` (green) | `W rejected` (red)
- **Progress bar**: visual indicator
- **Actions**: "Upload to LangSmith" button (enabled when accepted > 0), "Export review.jsonl" button
- **Keyboard shortcut hints** (small, muted)

#### Left Panel — Query List (resizable, default 300px)

**Filter bar** (sticky top):
- **Text search**: filters by query text, category, doc_id (keyboard: `/`)
- **Status filter**: All | Pending | Accepted | Rejected (button group)
- **Category dropdown**: auto-populated from loaded data (multi-select)
- **Language filter**: auto-populated from query_metadata.language
- **Doc ID filter**: auto-populated from citations[].doc_id
- **Additional toggles**: "Has typos only", "Modified citations only"
- **Item count**: "Showing X of Y items"

**Item list** (virtualized for performance):
- Each row shows:
  - Status indicator (colored dot: green/red/gray)
  - Query text (truncated, ~2 lines)
  - Category badge
  - Citation count badge (e.g., "2 citations")
  - "edited" badge if citations_modified
  - Language badge if non-English
- Click to select, keyboard navigation (j/k or arrows)

#### Center Panel — Detail Panel (flex-grow)

**Query section**:
- Full query text displayed prominently
- Query metadata shown as inline badges: language, tone, style, has_typos

**Citations section** (the key improvement over SAGE):
- List of all citations for this item
- Each citation card shows:
  - **Doc ID** with file icon
  - **Citation text** in a highlighted code/quote block
  - **Span indices** `[start_index:end_index]`
  - **Chunks** (collapsible)
  - **Actions per citation**: Remove (x button), Click to view in source panel
- **"Add Citation" button**: Opens the source panel in "selection mode" — user picks a doc from a dropdown, selects text, confirms → new citation appended
- When a citation is clicked, the right panel navigates to that doc and scrolls to the highlighted span

**Classification** (collapsible):
- Category, Subcategory (editable dropdowns? or read-only display)

**Sources** (collapsible):
- List of URLs from frontmatter

**Reviewer Notes**:
- Textarea, auto-saves on debounce (500ms)
- Keyboard: `n` to focus

**Action Buttons**:
- **Accept** (green, keyboard: `a`) — sets review_status to "accepted", auto-advances to next pending
- **Reject** (red, keyboard: `r`) — sets review_status to "rejected", auto-advances to next pending
- **Reset** (gray) — clears back to "pending"

#### Right Panel — Source Viewer (resizable, default 50%)

**Header**:
- **Document selector**: Dropdown of all KB docs (current doc highlighted). User can switch to any doc — this is how multi-doc citations work.
- **View toggle**: Raw | Preview (markdown rendered)
- **Span info**: Shows `[start:end]` for the currently highlighted citation

**Content area**:
- Full KB document content displayed
- **Citation highlights**: All citations for the current item that reference this doc are highlighted (yellow background, distinct colors for multiple)
- **Auto-scroll**: When a citation is selected in the center panel, scrolls to it
- **Text selection → "Add as Citation"**: When user selects text in the source viewer:
  - A floating button appears: "Add as Citation"
  - Click → backend computes span (compute_span from validation module)
  - If valid, citation is added to the item's citations list
  - `citations_modified` flag set to true
  - `original_citations` preserved on first edit

**Real Queries Panel** (optional, togglable):
- If real queries were loaded, a collapsible panel or tab shows them for style comparison
- Useful during review to check if synthetic queries match real patterns

---

## Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `j` / `↓` | Next item in filtered list |
| `k` / `↑` | Previous item in filtered list |
| `a` | Accept current item, advance to next pending |
| `r` | Reject current item, advance to next pending |
| `n` | Focus reviewer notes |
| `/` | Focus search box |
| `Escape` | Blur focused input / close modal |
| `1`-`9` | Jump to Nth citation in detail panel |

---

## Tech Stack

### Frontend
- **Framework**: Next.js (App Router)
- **Language**: TypeScript
- **Styling**: Tailwind CSS (dark theme)
- **State**: Zustand
- **Markdown rendering**: react-markdown + remark-gfm
- **List virtualization**: TanStack React Virtual
- **Font**: IBM Plex Mono (monospace)

### Backend
- **Framework**: FastAPI (Python)
- **Data persistence**: JSONL files (atomic writes via temp file + rename)
- **Citation validation**: Reuses `synthetic_datagen.validation.span_matcher.compute_span()`
- **LangSmith upload**: Reuses `synthetic_datagen.langsmith_upload.LangsmithUploader`
- **Concurrency**: Threading lock for review store writes

---

## API Endpoints

### Setup / Data Loading

```
POST /api/load/kb
  Body: { path: string }  (absolute path to KB directory)
  Response: { doc_count: int, doc_ids: string[] }
  Validates directory exists, contains .md files, loads into memory.

POST /api/load/output
  Body: { path: string }  (absolute path to output.jsonl)
  Response: { item_count: int }
  Parses JSONL, creates review.jsonl copy with review fields added.

POST /api/load/queries
  Body: { path: string }  (absolute path to queries.json)
  Response: { query_count: int }
  Optional. Loads real queries for reference display.
```

### Review Operations

```
GET /api/items
  Response: ReviewItem[]
  Returns all items from review.jsonl.

PATCH /api/items/{index}
  Body: Partial<ReviewItem>  (review_status, reviewer_notes, citations, citations_modified)
  Response: ReviewItem
  Updates item at index, persists to review.jsonl.

GET /api/kb/{doc_id}
  Response: { doc_id: string, content: string }
  Returns KB document content (frontmatter stripped). LRU cached.
```

### Citation Operations

```
POST /api/citation/compute
  Body: { doc_id: string, selected_text: string }
  Response: { found: bool, start_index: int, end_index: int }
  Computes exact span using span_matcher.compute_span().
```

### Export / Upload

```
POST /api/upload
  Body: { dataset_name: string }
  Response: { dataset_url: string, count: int }
  Uploads all accepted items to LangSmith via LangsmithUploader.

GET /api/export
  Response: File download (review.jsonl)
  Returns the current review.jsonl file.

GET /api/filters
  Response: { categories: string[], languages: string[], doc_ids: string[] }
  Returns unique filter values extracted from loaded data.
```

---

## File Structure

```
sieve/
├── project.md                    # This file
├── api/                          # Python FastAPI backend
│   ├── __init__.py
│   ├── main.py                   # FastAPI app, CORS, endpoints
│   ├── config.py                 # Runtime config (loaded paths, etc.)
│   ├── models.py                 # Pydantic models (ReviewItem, etc.)
│   └── services/
│       ├── review_store.py       # In-memory store backed by review.jsonl
│       ├── kb_store.py           # KB loading, frontmatter stripping, caching
│       ├── citation_service.py   # compute_span bridge
│       └── upload_service.py     # LangSmith upload bridge
├── src/
│   ├── app/
│   │   ├── page.tsx              # Main page (setup screen vs review screen)
│   │   ├── layout.tsx            # Root layout, fonts, metadata
│   │   └── globals.css           # Dark theme, custom scrollbars, highlights
│   ├── components/
│   │   ├── SetupScreen.tsx       # KB/output/queries file picker
│   │   ├── ReviewScreen.tsx      # Three-panel layout wrapper
│   │   ├── Toolbar.tsx           # Top bar with stats and actions
│   │   ├── Sidebar.tsx           # Query list with filters
│   │   ├── FilterBar.tsx         # Category/language/doc_id/status filters
│   │   ├── ItemRow.tsx           # Single item in the sidebar list
│   │   ├── DetailPanel.tsx       # Center panel: query, citations, actions
│   │   ├── CitationCard.tsx      # Single citation display with remove action
│   │   ├── AddCitationButton.tsx # Trigger for adding new citation
│   │   ├── SourceViewer.tsx      # Right panel: KB doc with highlights
│   │   ├── DocumentSelector.tsx  # Dropdown to switch KB documents
│   │   ├── CitationOverride.tsx  # Floating "Add as Citation" on text select
│   │   ├── UploadModal.tsx       # LangSmith upload dialog
│   │   ├── MetadataSection.tsx   # Collapsible metadata display
│   │   ├── RealQueriesPanel.tsx  # Optional: real queries reference
│   │   ├── ResizablePanels.tsx   # Drag-resizable three-panel layout
│   │   └── KeyboardHandler.tsx   # Global keyboard shortcut handler
│   ├── lib/
│   │   ├── api.ts                # API client functions
│   │   └── types.ts              # TypeScript type definitions
│   └── stores/
│       └── reviewStore.ts        # Zustand store for all review state
├── package.json
├── tsconfig.json
├── next.config.ts
├── tailwind.config.ts
└── run-dev.sh                    # Starts FastAPI + Next.js dev servers
```

---

## State Management (Zustand Store)

```typescript
interface ReviewStore {
  // Data
  items: ReviewItem[]
  kbDocs: string[]                      // List of loaded KB doc_ids
  realQueries: RealQuery[] | null       // Optional real queries
  isSetupComplete: boolean              // Whether KB + output are loaded

  // Selection
  selectedIndex: number | null

  // Filters
  filterStatus: "all" | "pending" | "accepted" | "rejected"
  filterCategories: string[]            // Selected categories (multi-select)
  filterLanguages: string[]             // Selected languages
  filterDocIds: string[]                // Selected doc_ids
  filterHasTypos: boolean | null        // null = any, true = only typos, false = no typos
  filterModifiedOnly: boolean           // Show only citation-modified items
  searchQuery: string

  // Derived
  filteredIndices: number[]             // Computed from filters + search
  stats: { total, reviewed, accepted, rejected, pending }

  // Actions
  loadKB(path: string): Promise<void>
  loadOutput(path: string): Promise<void>
  loadQueries(path: string): Promise<void>
  select(index: number): void
  selectNext(): void
  selectPrev(): void
  selectNextPending(): void
  setFilter(key, value): void
  setSearch(query: string): void
  updateItem(index: number, patch: Partial<ReviewItem>): Promise<void>
  addCitation(index: number, citation: Citation): Promise<void>
  removeCitation(index: number, citationIdx: number): Promise<void>
  acceptItem(): Promise<void>
  rejectItem(): Promise<void>
  resetItem(): Promise<void>
}
```

---

## Multi-Citation Workflow

This is the main feature differentiator from SAGE:

### Viewing Citations
- Center panel lists all citations as cards
- Each card shows doc_id, text, span indices
- Clicking a card scrolls the right panel to that document + highlights the span
- Multiple citations from the same doc show as multiple highlights

### Adding a Citation
1. User clicks "Add Citation" button in center panel
2. Right panel enters selection mode — document selector dropdown becomes active
3. User picks a KB document from the dropdown (can be different from current)
4. User selects text in the source viewer
5. Floating "Add as Citation" button appears
6. Click → `POST /api/citation/compute` validates the span
7. If valid, new citation is appended to the item's `citations` array
8. `citations_modified` = true, `original_citations` preserved (snapshot on first edit)

### Removing a Citation
1. Each citation card has a remove (x) button
2. Click → citation removed from array
3. If last citation removed, item still exists (0 citations)
4. `citations_modified` = true

### Editing a Citation
- No inline text editing (too error-prone for span alignment)
- Instead: remove old citation, add new one via text selection
- This ensures span indices are always computed correctly

---

## LangSmith Upload Format

Compatible with `rag_evaluation_framework.evaluation.metrics.token_level_base` which reads `outputs["references"]`:

```python
inputs = {"question": item.query}
outputs = {
    "references": [
        {"doc_id": c.doc_id, "start_index": c.start_index, "end_index": c.end_index}
        for c in item.citations
    ],
    "citation_texts": [c.text for c in item.citations],
    "chunks": [chunk for c in item.citations for chunk in c.chunks],
    "source": item.source,
}
metadata = {
    "category": item.category,
    "subcategory": item.subcategory,
    "review_status": "accepted",
    "citations_modified": item.citations_modified,
    "reviewer_notes": item.reviewer_notes,
}
```

---

## Dev Setup

```bash
# Terminal 1: Backend
cd sieve/api
pip install fastapi uvicorn
uvicorn main:app --reload --port 8000

# Terminal 2: Frontend
cd sieve
pnpm install
pnpm dev   # Next.js on port 3000
```

Or use the convenience script:
```bash
./run-dev.sh
```

---

## Integration with rag-evaluation-framework

SIEVE reuses two modules from the framework (imported directly, not copied):

1. **`synthetic_datagen.validation.span_matcher.compute_span()`** — for computing citation spans when user selects text
2. **`synthetic_datagen.langsmith_upload.LangsmithUploader`** — for uploading accepted items to LangSmith

The framework should be installed in the same Python environment:
```bash
pip install -e /path/to/rag-evaluation-framework[datagen]
```
